{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nModel Error Analysis for the Boston houses dataset\n===================================================================\n\nHere we train a RandomForestRegressor to predict the price of the houses\nin Boston. This is our primary model. Then we build a secondary model,\ncalled Model Performance Predictor (MPP), to predict on what samples\nthe primary model returns wrong or correct predictions. The MPP is a\nDecisionTree returning a binary outcome success/failure. The leaf nodes\nyielding failure outcome gather the samples mis-predicted by the primary\nmodel. Plotting the feature distributions of these samples and comparing\nto the whole data highlights the subpopulations where the model works poorly.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Those are the necessary imports and initializations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\n\nimport numpy as np\nimport random\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n\nfrom mea.error_analyzer import ErrorAnalyzer\nfrom mea.error_visualizer import ErrorVisualizer\n\n\ndefault_seed = 10\nnp.random.seed(default_seed)\nrandom.seed(default_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Boston houses dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = load_boston()\nX = dataset.data\ny = dataset.target\nfeature_names = dataset.feature_names\n\nX_train, X_test, y_train, y_test = train_test_split(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train a RandomForestRegressor.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = RandomForestRegressor()\nmodel.fit(X_train, y_train)\n\nr2_score = model.score(X_test, y_test)\nprint(\"R2 = %.2f\" % r2_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit a Model Performance Predictor on the model performances.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "error_analyzer = ErrorAnalyzer(model, feature_names=feature_names)\nerror_analyzer.fit(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print metrics regarding the Model Performance Predictor.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(error_analyzer.mpp_summary(X_test, y_test, output_dict=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the Model Performance Predictor Decision Tree.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "error_visualizer = ErrorVisualizer(error_analyzer)\ntree_src = error_visualizer.plot_error_tree()\n\n# the output of ``plot_error_tree`` is rendered automatically in a python notebook\n# the following is for rendering in this sphynx gallery\ntree_src.format = 'png'\ntree_src.render('tree')\ntree_img = mpimg.imread('tree.png')\n\nplt.figure(figsize=(20, 20))\nplt.imshow(tree_img)\nplt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the details regarding the decision tree nodes containing the majority of errors.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "error_analyzer.error_node_summary(leaf_selector=\"all_errors\", add_path_to_leaves=True, print_summary=True);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the feature distributions of samples in ``LEAF 12`` containing the majority of errors.\nRank features by correlation to error.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "error_visualizer.plot_feature_distributions_on_leaves(leaf_selector=12, top_k_features=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Discussion\n----------\n\nModel Performance Predictor Metrics\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWe are dealing with a regression task, but the metrics highlight the accuracy\nof the primary model and its estimate given by the Model Performance Predictor.\nHere the primary predictions of price have been categorized in two classes:\n'Correct prediction' and 'Wrong prediction' by thresholding the deviation of\nthe prediction from the true value. Close enough predictions are Correct prediction,\nthe others are Wrong prediction. For more details, have a look at the documentation.\nThe accuracy is then the number of Correct predictions over the total.\nThe MPP is representative of the behavior of the primary model as the true primary\naccuracy and the one estimated by the MPP are close.\n\nModel Failures\n^^^^^^^^^^^^^^\n\nLet's focus on the nodes of the MPP DecisionTree, in particular the leaf nodes\nof class 'Wrong prediction'. These leaves contain the majority of errors, each\nleaf clustering a subpopulation of errors with different feature values. The largest\nand purest failure nodes are highlighted when printing the error node summary, and\nalso when plotting the feature distributions in the node (``leaf_selector=\"all_errors\"``).\nFrom the feature distributions, sorted by correlation with the error, we can see that\nthe majority of problems occur for extreme values of features ``LSTAT`` and ``AGE``.\nIn the next iteration of model design, the primary model needs to be improved for these\nsubpopulations.\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}